{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "175942da-d963-400a-9a61-0ffce61fd6ff",
   "metadata": {},
   "source": [
    "# WS_follow_along_makemore_2.ipynb\n",
    "# WESmith 06/07/23\n",
    "## follow along with Karpathy video\n",
    "## https://www.youtube.com/watch?v=TCH_1BHY58I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92776de1-1eda-452d-b06f-e701da9e8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57228262-6398-429d-9ed4-a118f7ea885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('../names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac717a8-3164-4296-9642-6f08d94980a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a64fcb9-c22d-41eb-8dfa-394c4c365ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi  = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos   = {i:s for s, i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdae775-7c0c-447d-9f9e-412f4db92b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words, block_size=3):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        #print(w)\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            #print(''.join(itos[i] for i in context), '--->', ch)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709ef7f3-9609-43ad-bf60-ae4e1e6addd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "block_size = 3\n",
    "Xtr,  Ytr  = build_dataset(words[:n1],   block_size=block_size)\n",
    "Xdev, Ydev = build_dataset(words[n1:n2], block_size=block_size)\n",
    "Xte,  Yte  = build_dataset(words[n2:],   block_size=block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac35e02-861d-4f31-b4d5-502da5a4d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27, 2))  # embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66acab9-57c6-464f-8446-594d21445360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must cast one-hot to float() because C is float()\n",
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C # matrix multiplication to pull out a row of C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5875385b-0281-47df-a6a7-7c16e2e39e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "C[torch.tensor([5, 6, 7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f85bfcc-e9be-4540-850c-f5b39370415b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5356556c-e17d-4c9f-acab-4cb666c85569",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29c8e6e-e0b4-471f-9beb-5572b31b413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c79cc6-5ba2-42b2-911f-6cbe4c97bcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer of 100 neurons: three letters, each with 2D embedding: => 6 inputs to each neuron\n",
    "W1 = torch.randn((6, 100))\n",
    "b1 = torch.randn(100)  # biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f89fd-e823-4ef2-93b7-9675a3e943c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to transform emb into an N x 6 array for the NN\n",
    "# this is one way (that we won't use: it is ineffecient with memory)\n",
    "dd = torch.cat(torch.unbind(emb, 1), 1)\n",
    "dd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32190ba0-1703-47f3-92cd-e62c4daa5634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'view' tutorial here: it is efficient: no memory use\n",
    "a = torch.arange(18)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b9fbf4-cd5e-4447-b6d9-40d0b9839c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.view(2,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c426653-3b53-414d-a8aa-e259a5587361",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.view(3,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3bd09-ef76-448c-a445-026ab44a426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf81782-8877-4b51-88b8-2a463705e6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to transform emb into an N x 6 array for the NN\n",
    "emb.view(32, 6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd567b-0cba-4fcc-8edd-9dabd559a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions work; or can do emb.view(emb.shape[0], 6)\n",
    "# also be careful that b1 broadcasts correctly\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f36e1dd-4d9c-4ef3-9729-ed3fb36dbe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output layer: 27 neurons, 100 inputs to each\n",
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d00afc-01e6-48a5-9918-fbe4acaee797",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2dc454-5eb3-4283-ad82-8b3725ac0efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax\n",
    "counts = logits.exp()\n",
    "prob   = counts / counts.sum(1, keepdims=True)\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809f3e2-c43c-4f45-879c-7740bdc0f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get negative log likelihood\n",
    "loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b8b26b-2d82-4878-8f57-74d332d80ca8",
   "metadata": {},
   "source": [
    "# CLEAN UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9182ff-1ee9-4588-b658-93249b1a4f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr.shape, Ytr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7843d1-3566-42f7-a4e7-616d0f9f63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "block_size = 5  # number of characters to use for the prediction\n",
    "n          = 200 # number of neurons in hidden layer (started at 100)\n",
    "n_emb      = 15  # embedding dimension (was 2 to begin with)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a27634f-3437-4f42-b8fa-c094439786e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1],   block_size=block_size)\n",
    "Xdev, Ydev = build_dataset(words[n1:n2], block_size=block_size)\n",
    "Xte,  Yte  = build_dataset(words[n2:],   block_size=block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d282f19-bc2d-4052-92e7-860d6a068e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncharemb = n_emb * block_size\n",
    "g  = torch.Generator().manual_seed(2147483647)\n",
    "C  = torch.randn((27, n_emb), generator=g)\n",
    "W1 = torch.randn(( ncharemb, n), generator=g)\n",
    "b1 = torch.randn(n,       generator=g)\n",
    "W2 = torch.randn((n, 27), generator=g)\n",
    "b2 = torch.randn(27,      generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0df823-0bb5-4f4e-8efa-a266894ab50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.nelement() for p in parameters) # number of total parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ad2b2-a17c-45c8-bb3c-46417dae2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True  # False by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a78ba5-9d1a-4378-9689-e1b926bea705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrexp = torch.linspace(-3, 0, 1000)\n",
    "lrs   = 10**lrexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe7d21a-5124-4792-a2a3-f9c7ce8272b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lri   = []\n",
    "lossi = []\n",
    "stepi = []\n",
    "\n",
    "for i in range(20000):\n",
    "    \n",
    "    # minibatch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "    \n",
    "    # forward pass\n",
    "    emb    = C[Xtr[ix]]  # (batch_size, 3, 2)\n",
    "    h      = torch.tanh(emb.view(-1, ncharemb) @ W1 + b1)\n",
    "    logits = h @ W2 + b2  # (batch_size, 27)\n",
    "    #counts = logits.exp()\n",
    "    #prob   = counts / counts.sum(1, keepdims=True)\n",
    "    #loss   = -prob[torch.arange(32), Y].log().mean()\n",
    "    loss   = F.cross_entropy(logits, Ytr[ix]) # this replaces the above three lines: much more efficient\n",
    "    #print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    #lr = lrs[i]\n",
    "    lr = 0.02  # did most training at 0.1, then reduced in end stages\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "    # track stats\n",
    "    #lri.append(lrexp[i])  # use this to find best learning rates\n",
    "    stepi.append(i)\n",
    "    lossi.append(loss.log10().item())\n",
    "        \n",
    "loss.item() "
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7cd50a4-3905-4982-ae35-345770f97fd5",
   "metadata": {},
   "source": [
    "plt.plot(stepi, lossi)  # shows that 0.1 is a pretty good learning rate: set it above\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a2bf30-d77c-48e9-a673-dc30982ad9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at loss for full training dataset\n",
    "emb    = C[Xtr]\n",
    "h      = torch.tanh(emb.view(-1, ncharemb) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss   = F.cross_entropy(logits, Ytr)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b761ef-13a0-42a0-a646-adc0ed1ca7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at loss for dev or test dataset\n",
    "# Karpathy's best in the video for this set is 2.1701\n",
    "emb    = C[Xdev]\n",
    "h      = torch.tanh(emb.view(-1, ncharemb) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss   = F.cross_entropy(logits, Ydev)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c5bfbb1-22d1-4fc0-bb86-b137959ab2a9",
   "metadata": {},
   "source": [
    "# look at character embeddings: generalize to show all projections of ND space\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(C[:,0].data, C[:,1].data, s=200)\n",
    "for i in range(C.shape[0]):\n",
    "    plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha='center', va='center', color='white')\n",
    "plt.grid('minor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7eea89-25fa-455c-bbd7-bf3dd6dc0452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9f6cbd9-8956-40fc-bcd1-9846577078fe",
   "metadata": {},
   "source": [
    "# sample from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be6e6de-b8b7-43dd-9a83-be2a82fe3b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(12345+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bb1e2c-2ece-4ed2-a27c-f057c6053a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(20):\n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        emb = C[torch.tensor([context])]\n",
    "        h = torch.tanh(emb.view(1, ncharemb) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        probs  = F.softmax(logits, dim=1)\n",
    "        ix     = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daddab24-ccba-47db-ae1b-3032ae206933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a2e14b-a0d4-4c05-9c43-2341e89ae91a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
